{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOanlG8786B1gKUr4pe2Z8u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ud-UdxGJy6-",
        "outputId": "ea688980-135e-49c6-8ff6-8a1d7609adbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Benign): 0.7669902912621359\n",
            "F1 Score (Benign): 0.868131868131868\n",
            "Recall (Benign): 0.7669902912621359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Used BNB Algorithm and family is Benign\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'Benign' class\n",
        "benign_indices = (y_test == 'Benign')\n",
        "y_test_benign = y_test[benign_indices]\n",
        "y_pred_benign = y_pred[benign_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'Benign' class\n",
        "accuracy_benign = accuracy_score(y_test_benign, y_pred_benign)\n",
        "f1_benign = f1_score(y_test_benign, y_pred_benign, average='weighted')\n",
        "recall_benign = recall_score(y_test_benign, y_pred_benign, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'Benign' class\n",
        "print(\"Accuracy (Benign):\", accuracy_benign)\n",
        "print(\"F1 Score (Benign):\", f1_benign)\n",
        "print(\"Recall (Benign):\", recall_benign)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Used BNB Algorithm and family is cerber\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'Cerber' class\n",
        "cerber_indices = (y_test == 'Cerber')\n",
        "y_test_cerber = y_test[cerber_indices]\n",
        "y_pred_cerber = y_pred[cerber_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'Cerber' class\n",
        "accuracy_cerber = accuracy_score(y_test_cerber, y_pred_cerber)\n",
        "f1_cerber = f1_score(y_test_cerber, y_pred_cerber, average='weighted')\n",
        "recall_cerber = recall_score(y_test_cerber, y_pred_cerber, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'Cerber' class\n",
        "print(\"Accuracy (Cerber):\", accuracy_cerber)\n",
        "print(\"F1 Score (Cerber):\", f1_cerber)\n",
        "print(\"Recall (Cerber):\", recall_cerber)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv3vD3skPPR8",
        "outputId": "dd0371aa-d4cc-4127-e955-3ab251e97566"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Cerber): 0.9027027027027027\n",
            "F1 Score (Cerber): 0.9488636363636364\n",
            "Recall (Cerber): 0.9027027027027027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Used BNB Algorithm and family is Locky\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'Locky' class\n",
        "locky_indices = (y_test == 'Locky')\n",
        "y_test_locky = y_test[locky_indices]\n",
        "y_pred_locky = y_pred[locky_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'Locky' class\n",
        "accuracy_locky = accuracy_score(y_test_locky, y_pred_locky)\n",
        "f1_locky = f1_score(y_test_locky, y_pred_locky, average='weighted')\n",
        "recall_locky = recall_score(y_test_locky, y_pred_locky, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'Locky' class\n",
        "print(\"Accuracy (Locky):\", accuracy_locky)\n",
        "print(\"F1 Score (Locky):\", f1_locky)\n",
        "print(\"Recall (Locky):\", recall_locky)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtQ3xocFQGo7",
        "outputId": "e2816bdd-73ae-44aa-8663-783281523d9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Locky): 0.6944444444444444\n",
            "F1 Score (Locky): 0.819672131147541\n",
            "Recall (Locky): 0.6944444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Used BNB Algorithm and family is Reveton\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'Reveton' class\n",
        "reveton_indices = (y_test == 'Reveton')\n",
        "y_test_reveton = y_test[reveton_indices]\n",
        "y_pred_reveton = y_pred[reveton_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'Reveton' class\n",
        "accuracy_reveton = accuracy_score(y_test_reveton, y_pred_reveton)\n",
        "f1_reveton = f1_score(y_test_reveton, y_pred_reveton, average='weighted')\n",
        "recall_reveton = recall_score(y_test_reveton, y_pred_reveton, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'Reveton' class\n",
        "print(\"Accuracy (Reveton):\", accuracy_reveton)\n",
        "print(\"F1 Score (Reveton):\", f1_reveton)\n",
        "print(\"Recall (Reveton):\", recall_reveton)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ASgskuPQrVL",
        "outputId": "89c3be13-05c1-4db4-ace3-07479fb1336d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Reveton): 0.6538461538461539\n",
            "F1 Score (Reveton): 0.7906976744186047\n",
            "Recall (Reveton): 0.6538461538461539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'TeslaCrypt' class\n",
        "teslacrypt_indices = (y_test == 'TeslaCrypt')\n",
        "y_test_teslacrypt = y_test[teslacrypt_indices]\n",
        "y_pred_teslacrypt = y_pred[teslacrypt_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'TeslaCrypt' class\n",
        "accuracy_teslacrypt = accuracy_score(y_test_teslacrypt, y_pred_teslacrypt)\n",
        "f1_teslacrypt = f1_score(y_test_teslacrypt, y_pred_teslacrypt, average='weighted')\n",
        "recall_teslacrypt = recall_score(y_test_teslacrypt, y_pred_teslacrypt, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'TeslaCrypt' class\n",
        "print(\"Accuracy (TeslaCrypt):\", accuracy_teslacrypt)\n",
        "print(\"F1 Score (TeslaCrypt):\", f1_teslacrypt)\n",
        "print(\"Recall (TeslaCrypt):\", recall_teslacrypt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-6JSJsBRZRA",
        "outputId": "cd15400c-f5e2-490e-fc72-9a31df7fd12b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (TeslaCrypt): nan\n",
            "F1 Score (TeslaCrypt): 0.0\n",
            "Recall (TeslaCrypt): 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv(\"/Dataset.txt\", header=None)\n",
        "\n",
        "# Split the dataset into features (x) and target (y)\n",
        "x = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Resample the dataset to handle class imbalance\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.2, random_state=75)\n",
        "\n",
        "# Instantiate and train the Bernoulli Naive Bayes classifier\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "# Filter predictions and true labels for 'Yakes' class\n",
        "yakes_indices = (y_test == 'Yakes')\n",
        "y_test_yakes = y_test[yakes_indices]\n",
        "y_pred_yakes = y_pred[yakes_indices]\n",
        "\n",
        "# Calculate evaluation metrics for 'Yakes' class\n",
        "accuracy_yakes = accuracy_score(y_test_yakes, y_pred_yakes)\n",
        "f1_yakes = f1_score(y_test_yakes, y_pred_yakes, average='weighted')\n",
        "recall_yakes = recall_score(y_test_yakes, y_pred_yakes, average='weighted')\n",
        "\n",
        "# Printing the evaluation metrics for 'Yakes' class\n",
        "print(\"Accuracy (Yakes):\", accuracy_yakes)\n",
        "print(\"F1 Score (Yakes):\", f1_yakes)\n",
        "print(\"Recall (Yakes):\", recall_yakes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haVK7IeZR8Uz",
        "outputId": "bf23b698-ec5a-4f79-cf00-830d4210e45e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Yakes): 0.5347593582887701\n",
            "F1 Score (Yakes): 0.6968641114982579\n",
            "Recall (Yakes): 0.5347593582887701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}